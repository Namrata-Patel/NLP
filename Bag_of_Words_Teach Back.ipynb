{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "# Simple Example of Bag Of Words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: ['awesome' 'bad' 'good' 'is' 'it' 'not' 'this']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Word Vector ['awesome' 'bad' 'good' 'is' 'it' 'not' 'this']</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is good, is it not?</td>\n",
              "      <td>[This, is, good,, is, it, not?]</td>\n",
              "      <td>[0, 0, 1, 2, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is bad</td>\n",
              "      <td>[This, is, bad]</td>\n",
              "      <td>[0, 1, 0, 1, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is awesome</td>\n",
              "      <td>[This, is, awesome]</td>\n",
              "      <td>[1, 0, 0, 1, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Document                           Tokens  \\\n",
              "0  This is good, is it not?  [This, is, good,, is, it, not?]   \n",
              "1               This is bad                  [This, is, bad]   \n",
              "2           This is awesome              [This, is, awesome]   \n",
              "\n",
              "  Word Vector ['awesome' 'bad' 'good' 'is' 'it' 'not' 'this']  \n",
              "0                              [0, 0, 1, 2, 1, 1, 1]           \n",
              "1                              [0, 1, 0, 1, 0, 0, 1]           \n",
              "2                              [1, 0, 0, 1, 0, 0, 1]           "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Define the documents\n",
        "documents = [\n",
        "    \"This is good, is it not?\",\n",
        "    \"This is bad\",\n",
        "    \"This is awesome\"\n",
        "]\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the model and transform the documents into a document-term matrix\n",
        "bow_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Get the feature names (vocabulary)\n",
        "vocabulary = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert the matrix to an array\n",
        "bow_array = bow_matrix.toarray()\n",
        "\n",
        "print(\"Vocabulary:\", vocabulary)\n",
        "\n",
        "# Create a list of dictionaries for each document\n",
        "data = []\n",
        "for i, doc in enumerate(documents):\n",
        "    tokens = doc.split()  # Simple tokenization (may not handle punctuation properly)\n",
        "    word_vector = bow_array[i]\n",
        "    data.append({\"Document\": doc, \"Tokens\": tokens, f\"Word Vector {vocabulary}\": word_vector})\n",
        "\n",
        "# Create a DataFrame from the list of dictionaries\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Print the DataFrame\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpY-Zipd8od-",
        "toc": true
      },
      "source": [
        "# Applications of Bag Of Words (BOW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Document Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for new email: ['not spam']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sample documents and their corresponding labels (e.g., spam or not spam)\n",
        "documents = [\n",
        "    \"Win a free iPhone today!\",\n",
        "    \"Exclusive offer just for you\",\n",
        "    \"Dear friend, I need your help\",\n",
        "    \"Your account has been hacked\",\n",
        "    \"Congratulations! You've won a lottery\"\n",
        "]\n",
        "labels = ['spam', 'spam', 'not spam', 'not spam', 'spam']\n",
        "\n",
        "# Convert the documents into a Bag of Words model\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(documents)\n",
        "y = labels\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Naive Bayes classifier on the training data\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the spam/ham for a new email\n",
        "new_email = \"win a lottery\"\n",
        "#new_email = \"a leave application\"\n",
        "\n",
        "new_email_vectorized = vectorizer.transform([new_email])\n",
        "prediction = classifier.predict(new_email_vectorized)\n",
        "print(\"Prediction for new email:\", prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Document Classficiation Example 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for new review: ['positive']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sample documents and their corresponding labels (e.g., positive or negative)\n",
        "documents = [\n",
        "    \"I love this movie. It is fantastic!\",\n",
        "    \"Absolutely terrible. I will never watch this again.\",\n",
        "    \"Best film ever. I highly recommend it.\",\n",
        "    \"Awful. Complete waste of time.\",\n",
        "    \"Such a bad movie\",\n",
        "    \"I enjoyed this movie. It was great!\"\n",
        "]\n",
        "labels = ['positive', 'negative', 'positive', 'negative','negative', 'positive']\n",
        "\n",
        "# Convert the documents into a Bag of Words model\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(documents)\n",
        "y = labels\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Multinomial Naive Bayes classifier on the training data\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "new_review = \"a horrible movie\"\n",
        "#new_review = \"great music\"\n",
        "\n",
        "new_review_vectorized = vectorizer.transform([new_review])\n",
        "prediction = classifier.predict(new_review_vectorized)\n",
        "print(\"Prediction for new review:\", prediction)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for new review: ['negative']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Sample reviews and their corresponding sentiments (positive or negative)\n",
        "reviews = [\n",
        "    \"This movie was fantastic! I loved it.\",\n",
        "    \"Horrible movie. I hated it.\",\n",
        "    \"The plot was boring, but the acting was good.\",\n",
        "    \"I wouldn't recommend this movie.\",\n",
        "    \"Definitely a must-watch!\"\n",
        "]\n",
        "sentiments = ['positive', 'negative', 'neutral', 'negative', 'positive']\n",
        "\n",
        "# Convert the reviews into a Bag of Words model\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(reviews)\n",
        "y = sentiments\n",
        "\n",
        "# Train a Logistic Regression classifier on the data\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X, y)\n",
        "\n",
        "# Predict the sentiment for a new review\n",
        "new_review = \"The movie was not bad, but it could have been better.\"\n",
        "new_review_vectorized = vectorizer.transform([new_review])\n",
        "prediction = classifier.predict(new_review_vectorized)\n",
        "print(\"Prediction for new review:\", prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sentiment Analaysis using TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: I love this product. It is amazing!\n",
            "Vector: [1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Terrible service. I will never come back.\n",
            "Vector: [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0]\n",
            "Sentiment: Negative\n",
            "\n",
            "Review: The food was delicious. Highly recommend!\n",
            "Vector: [0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0]\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Worst experience ever. Do not go there.\n",
            "Vector: [0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1]\n",
            "Sentiment: Negative\n",
            "\n",
            "Review: Great movie. I enjoyed it a lot!\n",
            "Vector: [0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Sentiment: Positive\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample reviews\n",
        "reviews = [\n",
        "    \"I love this product. It is amazing!\",\n",
        "    \"Terrible service. I will never come back.\",\n",
        "    \"The food was delicious. Highly recommend!\",\n",
        "    \"Worst experience ever. Do not go there.\",\n",
        "    \"Great movie. I enjoyed it a lot!\"\n",
        "]\n",
        "\n",
        "# Convert the reviews into a Bag of Words model\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(reviews)\n",
        "\n",
        "# Analyze the sentiment of each review\n",
        "for review, vector in zip(reviews, X.toarray()):\n",
        "    blob = TextBlob(review)\n",
        "    sentiment = blob.sentiment.polarity\n",
        "    print(f\"Review: {review}\")\n",
        "    print(f\"Vector: {vector}\")\n",
        "    print(f\"Sentiment: {'Positive' if sentiment > 0 else 'Negative' if sentiment < 0 else 'Neutral'}\")\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Bag of Words.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
