{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "# Simple Example of Bag Of Words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: ['cat' 'chased' 'dog' 'log' 'mat' 'on' 'sat' 'the']\n",
            "Bag of Words Matrix:\n",
            " [[1 0 0 0 1 1 1 2]\n",
            " [0 0 1 1 0 1 1 2]\n",
            " [1 1 1 0 0 0 0 2]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Define the documents\n",
        "documents = [\n",
        "    \"The cat sat on the mat.\",\n",
        "    \"The dog sat on the log.\",\n",
        "    \"The cat chased the dog.\"\n",
        "]\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the model and transform the documents into a document-term matrix\n",
        "bow_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Get the feature names (vocabulary)\n",
        "vocabulary = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert the matrix to an array and print the result\n",
        "bow_array = bow_matrix.toarray()\n",
        "print(\"Vocabulary:\", vocabulary)\n",
        "print(\"Bag of Words Matrix:\\n\", bow_array)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpY-Zipd8od-",
        "toc": true
      },
      "source": [
        "# Applications of Bag Of Words (BOW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Document Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<5x22 sparse matrix of type '<class 'numpy.int64'>'\n",
              " \twith 24 stored elements in Compressed Sparse Row format>,\n",
              " ['spam', 'spam', 'not spam', 'not spam', 'spam'])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sample documents and their corresponding labels (e.g., spam or not spam)\n",
        "documents = [\n",
        "    \"Win a free iPhone today!\",\n",
        "    \"Exclusive offer just for you\",\n",
        "    \"Dear friend, I need your help\",\n",
        "    \"Your account has been hacked\",\n",
        "    \"Congratulations! You've won a lottery\"\n",
        "]\n",
        "labels = ['spam', 'spam', 'not spam', 'not spam', 'spam']\n",
        "\n",
        "# Convert the documents into a Bag of Words model\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(documents)\n",
        "y = labels\n",
        "\n",
        "X , y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Naive Bayes classifier on the training data\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "predictions = classifier.predict(X_test)\n",
        "print(\"Predictions:\", predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for new review: ['negative']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Sample reviews and their corresponding sentiments (positive or negative)\n",
        "reviews = [\n",
        "    \"This movie was fantastic! I loved it.\",\n",
        "    \"Horrible movie. I hated it.\",\n",
        "    \"The plot was boring, but the acting was good.\",\n",
        "    \"I wouldn't recommend this movie.\",\n",
        "    \"Definitely a must-watch!\"\n",
        "]\n",
        "sentiments = ['positive', 'negative', 'neutral', 'negative', 'positive']\n",
        "\n",
        "# Convert the reviews into a Bag of Words model\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(reviews)\n",
        "y = sentiments\n",
        "\n",
        "# Train a Logistic Regression classifier on the data\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X, y)\n",
        "\n",
        "# Predict the sentiment for a new review\n",
        "new_review = \"The movie was not bad, but it could have been better.\"\n",
        "new_review_vectorized = vectorizer.transform([new_review])\n",
        "prediction = classifier.predict(new_review_vectorized)\n",
        "print(\"Prediction for new review:\", prediction)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Bag of Words.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
